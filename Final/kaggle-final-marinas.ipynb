{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "198c57eb-5d38-4859-bc15-7869869f6157",
   "metadata": {},
   "source": [
    "# CalCOFI Ocean chemistry prediction\n",
    "EDS 232 - Machine Learning\n",
    "\n",
    "March 18, 2025\n",
    "\n",
    "Marina Kochuten\n",
    "\n",
    "Team: Bailey Jorgensen, Jordan Sibley, Nicole Pepper\n",
    "\n",
    "## Your Task\n",
    "\n",
    "- Acquire domain knowledge provided by Dr. Satterthwaite in her presentation\n",
    "- Explore the data\n",
    "- Load the dataset and perform initial exploratory data analysis to inform your modeling choices\n",
    "- Preprocessing (if necessary)\n",
    "- Is the data ready to be used in your model?\n",
    "- Choose and train a model\n",
    "- Select an appropriate machine learning algorithm for this task\n",
    "- Train your model on the provided training data\n",
    "- Tune relevant parameters\n",
    "- Use cross-validation to optimize model performance\n",
    "- Experiment with different hyperparameters to reduce error\n",
    "- Submit your prediction\n",
    "- Generate predictions on the provided test dataset\n",
    "\n",
    "## Data\n",
    "\n",
    "This dataset was downloaded from the CalCOFI data portal. Bottle and cast data was downloaded and merged, then relevant variables were selected.\n",
    "\n",
    "You will use the data contained in the train.csv file to train a model that will predict dissolved inorganic carbon (DIC) content in the water samples.\n",
    "\n",
    "A database description is available here: https://calcofi.org/data/oceanographic-data/bottle-database/\n",
    "\n",
    "Files\n",
    "\n",
    "- train.csv: the training set\n",
    "- test.csv: the test set\n",
    "\n",
    "\n",
    "## Variables\n",
    "\n",
    "- Lat_Dec: Observed Latitude in decimal degrees\n",
    "- Lon_Dec: Observed Longitude in decimal degrees\n",
    "- NO2uM: Micromoles Nitrite per liter of seawater\n",
    "- NO3uM: Micromoles Nitrate per liter of seawater\n",
    "- NH3uM: Micromoles Ammonia per liter of seawater\n",
    "- R_TEMP: Reported (Potential) Temperature in degrees Celsius\n",
    "- R_Depth: Reported Depth (from pressure) in meters\n",
    "- R_Sal: Reported Salinity (from Specific Volume Anomoly, MÂ³/Kg)\n",
    "- R_DYNHT: Reported Dynamic Height in units of dynamic meters (work per unit mass)\n",
    "- R_Nuts: Reported Ammonium concentration\n",
    "- R_Oxy_micromol.Kg: Reported Oxygen micromoles/kilogram\n",
    "- PO4uM: Micromoles Phosphate per liter of seawater\n",
    "- SiO3uM: Micromoles Silicate per liter of seawater\n",
    "- TA1: Total Alkalinity micromoles per kilogram solution\n",
    "- Salinity1: Salinity (Practical Salinity Scale 1978)??\n",
    "- Temperature_degC: Not included in description but some other temperature measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe2c330-0c23-4a2d-b250-26760ed27e32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import uniform, randint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf82153-31c5-4f21-92fc-d22223cadcf7",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f763deb3-02a9-422e-9679-f6b965b9f31d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Lat_Dec</th>\n",
       "      <th>Lon_Dec</th>\n",
       "      <th>NO2uM</th>\n",
       "      <th>NO3uM</th>\n",
       "      <th>NH3uM</th>\n",
       "      <th>R_TEMP</th>\n",
       "      <th>R_Depth</th>\n",
       "      <th>R_Sal</th>\n",
       "      <th>R_DYNHT</th>\n",
       "      <th>R_Nuts</th>\n",
       "      <th>R_Oxy_micromol.Kg</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>PO4uM</th>\n",
       "      <th>SiO3uM</th>\n",
       "      <th>TA1.x</th>\n",
       "      <th>Salinity1</th>\n",
       "      <th>Temperature_degC</th>\n",
       "      <th>DIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>34.385030</td>\n",
       "      <td>-120.665530</td>\n",
       "      <td>0.030</td>\n",
       "      <td>33.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.79</td>\n",
       "      <td>323</td>\n",
       "      <td>141.2</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.40948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.77</td>\n",
       "      <td>53.86</td>\n",
       "      <td>2287.45</td>\n",
       "      <td>34.198</td>\n",
       "      <td>7.82</td>\n",
       "      <td>2270.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>31.418333</td>\n",
       "      <td>-121.998333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>34.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.12</td>\n",
       "      <td>323</td>\n",
       "      <td>140.8</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.81441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.57</td>\n",
       "      <td>52.50</td>\n",
       "      <td>2279.10</td>\n",
       "      <td>34.074</td>\n",
       "      <td>7.15</td>\n",
       "      <td>2254.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>34.385030</td>\n",
       "      <td>-120.665530</td>\n",
       "      <td>0.180</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.68</td>\n",
       "      <td>50</td>\n",
       "      <td>246.8</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.29150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.29</td>\n",
       "      <td>13.01</td>\n",
       "      <td>2230.80</td>\n",
       "      <td>33.537</td>\n",
       "      <td>11.68</td>\n",
       "      <td>2111.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>33.482580</td>\n",
       "      <td>-122.533070</td>\n",
       "      <td>0.013</td>\n",
       "      <td>29.67</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.33</td>\n",
       "      <td>232</td>\n",
       "      <td>158.5</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.01</td>\n",
       "      <td>89.62595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.27</td>\n",
       "      <td>38.98</td>\n",
       "      <td>2265.85</td>\n",
       "      <td>34.048</td>\n",
       "      <td>8.36</td>\n",
       "      <td>2223.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>31.414320</td>\n",
       "      <td>-121.997670</td>\n",
       "      <td>0.000</td>\n",
       "      <td>33.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7.53</td>\n",
       "      <td>323</td>\n",
       "      <td>143.4</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.05</td>\n",
       "      <td>60.03062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.53</td>\n",
       "      <td>49.28</td>\n",
       "      <td>2278.49</td>\n",
       "      <td>34.117</td>\n",
       "      <td>7.57</td>\n",
       "      <td>2252.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    Lat_Dec     Lon_Dec  NO2uM  NO3uM  NH3uM  R_TEMP  R_Depth  R_Sal  \\\n",
       "0   1  34.385030 -120.665530  0.030  33.80   0.00    7.79      323  141.2   \n",
       "1   2  31.418333 -121.998333  0.000  34.70   0.00    7.12      323  140.8   \n",
       "2   3  34.385030 -120.665530  0.180  14.20   0.00   11.68       50  246.8   \n",
       "3   4  33.482580 -122.533070  0.013  29.67   0.01    8.33      232  158.5   \n",
       "4   5  31.414320 -121.997670  0.000  33.10   0.05    7.53      323  143.4   \n",
       "\n",
       "   R_DYNHT  R_Nuts  R_Oxy_micromol.Kg  Unnamed: 12  PO4uM  SiO3uM    TA1.x  \\\n",
       "0    0.642    0.00           37.40948          NaN   2.77   53.86  2287.45   \n",
       "1    0.767    0.00           64.81441          NaN   2.57   52.50  2279.10   \n",
       "2    0.144    0.00          180.29150          NaN   1.29   13.01  2230.80   \n",
       "3    0.562    0.01           89.62595          NaN   2.27   38.98  2265.85   \n",
       "4    0.740    0.05           60.03062          NaN   2.53   49.28  2278.49   \n",
       "\n",
       "   Salinity1  Temperature_degC      DIC  \n",
       "0     34.198              7.82  2270.17  \n",
       "1     34.074              7.15  2254.10  \n",
       "2     33.537             11.68  2111.04  \n",
       "3     34.048              8.36  2223.41  \n",
       "4     34.117              7.57  2252.62  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv('train.csv')\n",
    "final_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Look at the training data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f28c17a-555e-42d0-88b4-3b485e3c8670",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Lat_Dec</th>\n",
       "      <th>Lon_Dec</th>\n",
       "      <th>NO2uM</th>\n",
       "      <th>NO3uM</th>\n",
       "      <th>NH3uM</th>\n",
       "      <th>R_TEMP</th>\n",
       "      <th>R_Depth</th>\n",
       "      <th>R_Sal</th>\n",
       "      <th>R_DYNHT</th>\n",
       "      <th>R_Nuts</th>\n",
       "      <th>R_Oxy_micromol.Kg</th>\n",
       "      <th>PO4uM</th>\n",
       "      <th>SiO3uM</th>\n",
       "      <th>TA1</th>\n",
       "      <th>Salinity1</th>\n",
       "      <th>Temperature_degC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1455</td>\n",
       "      <td>34.321666</td>\n",
       "      <td>-120.811666</td>\n",
       "      <td>0.02</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9.51</td>\n",
       "      <td>101</td>\n",
       "      <td>189.9</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.41</td>\n",
       "      <td>138.838300</td>\n",
       "      <td>1.85</td>\n",
       "      <td>25.5</td>\n",
       "      <td>2244.94</td>\n",
       "      <td>33.830</td>\n",
       "      <td>9.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1456</td>\n",
       "      <td>34.275000</td>\n",
       "      <td>-120.033333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.84</td>\n",
       "      <td>102</td>\n",
       "      <td>185.2</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.00</td>\n",
       "      <td>102.709200</td>\n",
       "      <td>2.06</td>\n",
       "      <td>28.3</td>\n",
       "      <td>2253.27</td>\n",
       "      <td>33.963</td>\n",
       "      <td>9.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1457</td>\n",
       "      <td>34.275000</td>\n",
       "      <td>-120.033333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.60</td>\n",
       "      <td>514</td>\n",
       "      <td>124.1</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.174548</td>\n",
       "      <td>3.40</td>\n",
       "      <td>88.1</td>\n",
       "      <td>2316.95</td>\n",
       "      <td>34.241</td>\n",
       "      <td>6.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1458</td>\n",
       "      <td>33.828333</td>\n",
       "      <td>-118.625000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>19.21</td>\n",
       "      <td>1</td>\n",
       "      <td>408.1</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.20</td>\n",
       "      <td>258.674300</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2240.49</td>\n",
       "      <td>33.465</td>\n",
       "      <td>19.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1459</td>\n",
       "      <td>33.828333</td>\n",
       "      <td>-118.625000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.65</td>\n",
       "      <td>100</td>\n",
       "      <td>215.5</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.00</td>\n",
       "      <td>145.839900</td>\n",
       "      <td>1.64</td>\n",
       "      <td>19.4</td>\n",
       "      <td>2238.30</td>\n",
       "      <td>33.720</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id    Lat_Dec     Lon_Dec  NO2uM  NO3uM  NH3uM  R_TEMP  R_Depth  R_Sal  \\\n",
       "0  1455  34.321666 -120.811666   0.02   24.0   0.41    9.51      101  189.9   \n",
       "1  1456  34.275000 -120.033333   0.00   25.1   0.00    9.84      102  185.2   \n",
       "2  1457  34.275000 -120.033333   0.00   31.9   0.00    6.60      514  124.1   \n",
       "3  1458  33.828333 -118.625000   0.00    0.0   0.20   19.21        1  408.1   \n",
       "4  1459  33.828333 -118.625000   0.02   19.7   0.00   10.65      100  215.5   \n",
       "\n",
       "   R_DYNHT  R_Nuts  R_Oxy_micromol.Kg  PO4uM  SiO3uM      TA1  Salinity1  \\\n",
       "0    0.258    0.41         138.838300   1.85    25.5  2244.94     33.830   \n",
       "1    0.264    0.00         102.709200   2.06    28.3  2253.27     33.963   \n",
       "2    0.874    0.00           2.174548   3.40    88.1  2316.95     34.241   \n",
       "3    0.004    0.20         258.674300   0.27     2.5  2240.49     33.465   \n",
       "4    0.274    0.00         145.839900   1.64    19.4  2238.30     33.720   \n",
       "\n",
       "   Temperature_degC  \n",
       "0              9.52  \n",
       "1              9.85  \n",
       "2              6.65  \n",
       "3             19.21  \n",
       "4             10.66  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the testing data\n",
    "final_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fd1b310-903d-4b34-aa17-c0d0141a237f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1454, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9305ec4-3adf-4a97-b90f-5b1da75468c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1454"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is Unnamed 12 all NA?\n",
    "df['Unnamed: 12'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "720389cb-716d-4d77-b02c-43e877daa809",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Lat_Dec', 'Lon_Dec', 'NO2uM', 'NO3uM', 'NH3uM', 'R_TEMP',\n",
       "       'R_Depth', 'R_Sal', 'R_DYNHT', 'R_Nuts', 'R_Oxy_micromol.Kg', 'PO4uM',\n",
       "       'SiO3uM', 'TA1.x', 'Salinity1', 'Temperature_degC', 'DIC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop `Unnamed: 12`\n",
    "df = df.drop('Unnamed: 12', axis = 1)\n",
    "\n",
    "# Confirm dropping worked\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b529fa0-c8dd-4a6f-bb8d-cf477e776b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df.drop('DIC', axis = 1)\n",
    "y = df['DIC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13f6c6ec-bad2-43dc-8def-4e8d16dbc381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename `TA1.x` in train data to match test (to fix error when scaling)\n",
    "X.rename(columns={'TA1.x': 'TA1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff06ed93-77e5-4e26-b769-c1cdc7421c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 808)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c472ab0-614c-4c0a-8803-79072870921f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale X values\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d15fe-8e1c-4e13-a9d0-68d56b597075",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95115c82-5576-4f79-a08f-2c5f60aa0f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVM Best RMSE Train: 5.367844886462071\n",
      "SVM Best RMSE Test: 7.243489280603425\n"
     ]
    }
   ],
   "source": [
    "# Initalize SVM regressor\n",
    "svm = SVR()\n",
    "\n",
    "# Initalize KFold CV object\n",
    "svm_kfold = KFold(n_splits = 5)\n",
    "\n",
    "# Set up parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Set up GridSearch\n",
    "gs_svm = GridSearchCV(svm, param_grid, cv = svm_kfold, n_jobs = 5, verbose = 0)\n",
    "\n",
    "# Fit grid search\n",
    "gs_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best SVM Parameters: {gs_svm.best_params_}\")\n",
    "\n",
    "# Initalize best SVM model\n",
    "svm_best = SVR(**gs_svm.best_params_)\n",
    "\n",
    "# Train SVM model\n",
    "svm_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate SVM predictions\n",
    "svm_best_pred_train = svm_best.predict(X_train_scaled)\n",
    "svm_best_pred_test = svm_best.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE\n",
    "svm_rmse_train = np.sqrt(mean_squared_error(y_train, svm_best_pred_train))\n",
    "svm_rmse_test = np.sqrt(mean_squared_error(y_test, svm_best_pred_test))\n",
    "print(f\"SVM Best RMSE Train: {svm_rmse_train}\")\n",
    "print(f\"SVM Best RMSE Test: {svm_rmse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e43004-edfb-44a9-abd7-0d6436a53564",
   "metadata": {},
   "source": [
    "## XG Boost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e07e879-018c-4d07-b28f-7007449a5709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split train one more time to have eval data\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 808)\n",
    "\n",
    "# Scale features\n",
    "X_train2_scaled = scaler.fit_transform(X_train2)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ebe0602-5822-4e25-8e91-f63cfe9d3cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of trees: 743\n"
     ]
    }
   ],
   "source": [
    "# Create XGB model\n",
    "xgb_model1 = xgb.XGBRegressor(n_estimators = 1000,\n",
    "                              learning_rate = 0.1,\n",
    "                              eval_metric = \"rmse\", \n",
    "                              early_stopping_rounds = 100,\n",
    "                              random_state = 808,\n",
    "                              n_jobs = 5)\n",
    "\n",
    "# Fit model\n",
    "xgb_model1.fit(X_train2_scaled, y_train2, eval_set = [(X_val_scaled, y_val)], verbose = 0)\n",
    "\n",
    "# Get the best number of trees\n",
    "best_num_trees = xgb_model1.best_iteration\n",
    "\n",
    "# Print the best number of trees\n",
    "print(f\"Best number of trees: {best_num_trees}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44e0cf29-d85f-4f19-99de-7aa1dc5f1318",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate: 0.054415222825961285\n"
     ]
    }
   ],
   "source": [
    "# Tune learning rate\n",
    "xgb_model2 = xgb.XGBRegressor(n_estimators = best_num_trees,\n",
    "                              eval_metric = \"rmse\", \n",
    "                              random_state = 808,\n",
    "                              n_jobs = 5)\n",
    "\n",
    "# Define hyperparameter distributions\n",
    "param_dist = {\n",
    "    \"learning_rate\":uniform(0.001, 0.5)\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(xgb_model2, \n",
    "                                   param_dist, \n",
    "                                   n_iter = 20,\n",
    "                                   cv = 5,  \n",
    "                                   random_state = 808)\n",
    "\n",
    "# Run random search\n",
    "random_search.fit(X_train2_scaled, y_train2, verbose = 0)\n",
    "\n",
    "# Print the best learning rate\n",
    "best_learning_rate = random_search.best_params_['learning_rate']\n",
    "print(f\"Best learning rate: {best_learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ee17a96-483d-49ca-b35f-bc573048bb60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'gamma': 0.14742953267361908, 'max_depth': 6, 'min_child_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "# Tune tree specific params\n",
    "\n",
    "# Initialize model using best number of trees and learning rate\n",
    "xgb_model3 = xgb.XGBRegressor(n_estimators = best_num_trees,\n",
    "                              learning_rate = best_learning_rate,\n",
    "                              eval_metric = \"rmse\", \n",
    "                              random_state = 808,\n",
    "                             # cv = 5,\n",
    "                              n_jobs = 5)\n",
    "                             # verbose = 0)\n",
    "\n",
    "# Define parameter dictionary\n",
    "param_dict = {\n",
    "    \"max_depth\": randint(3,8),  #randint upper bound is not inclusive: [a,b)\n",
    "    \"min_child_weight\": randint(1,8),\n",
    "    \"gamma\": uniform(0.05, 0.2)\n",
    "}\n",
    "\n",
    "# Set up new RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(xgb_model3, \n",
    "                                   param_dict, \n",
    "                                   n_iter = 20,\n",
    "                                   cv = 5, \n",
    "                                   random_state = 808,\n",
    "                                   n_jobs = 5)\n",
    "\n",
    "# Run random search\n",
    "random_search.fit(X_train2_scaled, y_train2, verbose = 0)\n",
    "\n",
    "# Print best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "047018fe-9358-4547-a446-fc9a3c4cabc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.8107414551062586, 'subsample': 0.5657684073330207}\n"
     ]
    }
   ],
   "source": [
    "# Tune stochastic components\n",
    "\n",
    "# Initialize model\n",
    "xgb_model4 = xgb.XGBRegressor(n_estimators = best_num_trees,\n",
    "                              learning_rate = best_learning_rate,\n",
    "                              gamma = 0.14742953267361908,\n",
    "                              max_depth = 6,\n",
    "                              min_child_weight = 1,\n",
    "                              eval_metric = \"rmse\", \n",
    "                              random_state = 808)\n",
    "\n",
    "# Define parameter dictionary\n",
    "param_dict = {\n",
    "    \"subsample\": uniform(0.5, 0.5),\n",
    "    \"colsample_bytree\": uniform(0.5, 0.5),\n",
    "}\n",
    "\n",
    "# Set up new RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(xgb_model4, \n",
    "                                   param_dict, \n",
    "                                   n_iter = 20,\n",
    "                                   cv = 5, \n",
    "                                   random_state = 808,\n",
    "                                   n_jobs = 5)\n",
    "\n",
    "# Run random search\n",
    "random_search.fit(X_train2_scaled, y_train2, verbose = 0)\n",
    "\n",
    "# Print best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fce735b8-b284-4471-97c9-fd548745947d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE Train: 0.21302371684553612\n",
      "XGBoost RMSE Test: 6.614784065005989\n"
     ]
    }
   ],
   "source": [
    "# Final model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators = best_num_trees,\n",
    "                              learning_rate = best_learning_rate,\n",
    "                              gamma = 0.14742953267361908,\n",
    "                              max_depth = 6,\n",
    "                              min_child_weight = 1,\n",
    "                              eval_metric = \"rmse\", \n",
    "                              random_state = 808,\n",
    "                             subsample = 0.5657684073330207,\n",
    "                             colsample_bytree = 0.8107414551062586)\n",
    "\n",
    "# Fit to full training data\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "xgb_pred_train = xgb_model.predict(X_train_scaled)\n",
    "xgb_pred_test = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE\n",
    "xgb_rmse_train = np.sqrt(mean_squared_error(y_train, xgb_pred_train))\n",
    "xgb_rmse_test = np.sqrt(mean_squared_error(y_test, xgb_pred_test))\n",
    "print(f\"XGBoost RMSE Train: {xgb_rmse_train}\")\n",
    "print(f\"XGBoost RMSE Test: {xgb_rmse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d502e6ea-1759-40ad-b9a6-056cce2e3457",
   "metadata": {},
   "source": [
    "## Decision Tree & KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f83bbc7-5eed-4309-abdb-dbdba3a59223",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN RMSE Train: 9.14596056848805\n",
      "KNN RMSE Test: 12.529606465726378\n",
      "DT RMSE Train: 0.0\n",
      "DT RMSE Test: 9.070576276949653\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "knn = KNeighborsRegressor(n_neighbors = 5)\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# Train (fit) both models\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_y_train_pred = knn.predict(X_train_scaled)\n",
    "dt_y_train_pred = dt.predict(X_train_scaled)\n",
    "knn_y_test_pred = knn.predict(X_test_scaled)\n",
    "dt_y_test_pred = dt.predict(X_test_scaled)\n",
    "\n",
    "# Compute RMSE\n",
    "knn_train_rmse = np.sqrt(mean_squared_error(y_train, knn_y_train_pred))\n",
    "knn_test_rmse = np.sqrt(mean_squared_error(y_test, knn_y_test_pred))\n",
    "dt_train_rmse = np.sqrt(mean_squared_error(y_train, dt_y_train_pred))\n",
    "dt_test_rmse = np.sqrt(mean_squared_error(y_test, dt_y_test_pred))\n",
    "\n",
    "#Print training accuracy for both models\n",
    "print(f'KNN RMSE Train: {knn_train_rmse}')\n",
    "print(f'KNN RMSE Test: {knn_test_rmse}')\n",
    "print(f'DT RMSE Train: {dt_train_rmse}')\n",
    "print(f'DT RMSE Test: {dt_test_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c76201-d776-40a8-bf63-cc71d86825d9",
   "metadata": {},
   "source": [
    "## Bagged tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "701e5e77-22e4-4c30-b00e-84ff6ebf29fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging training RMSE: 3.5750039035816723\n",
      "Bagging test RMSE: 7.081236805874178\n"
     ]
    }
   ],
   "source": [
    "# Initialize bagging classifier\n",
    "bagging = BaggingRegressor(n_estimators = 100,\n",
    "                           max_samples = 0.5,\n",
    "                            bootstrap = True,\n",
    "                            random_state = 808)\n",
    "\n",
    "# Train the model\n",
    "bagging.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "bagging_preds_train = bagging.predict(X_train_scaled)\n",
    "bagging_preds_test = bagging.predict(X_test_scaled)\n",
    "\n",
    "# Compute rmse\n",
    "bag_train_rmse = np.sqrt(mean_squared_error(y_train, bagging_preds_train))\n",
    "bag_test_rmse = np.sqrt(mean_squared_error(y_test, bagging_preds_test))\n",
    "\n",
    "#Print training accuracy for both models\n",
    "print(f'Bagging training RMSE: {bag_train_rmse}')\n",
    "print(f'Bagging test RMSE: {bag_test_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db655177-4905-42ed-a0a4-1b92e089eb76",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8611416-2fcd-49cf-9fbc-ac9255e45fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR RMSE Train: 5.1813774806839445\n",
      "LR RMSE Test: 6.724247896221981\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model\n",
    "lr = LinearRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lr_pred_train = lr.predict(X_train_scaled)\n",
    "lr_pred_test = lr.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE\n",
    "lr_rmse_train = np.sqrt(mean_squared_error(y_train, lr_pred_train))\n",
    "lr_rmse_test = np.sqrt(mean_squared_error(y_test, lr_pred_test))\n",
    "\n",
    "print(f'LR RMSE Train: {lr_rmse_train}')\n",
    "print(f'LR RMSE Test: {lr_rmse_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcdea14-bba1-4372-866a-6fc10d7db0d2",
   "metadata": {},
   "source": [
    "## Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "574efc32-a48e-4dac-b0ec-3f9a9b198003",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly LR RMSE Train: 3.70118553972158\n",
      "Poly LR RMSE Test: 15.74800385502208\n"
     ]
    }
   ],
   "source": [
    "# Transform features to include polynomial terms (degree 2 for quadratic terms)\n",
    "poly = PolynomialFeatures(2, include_bias = False)\n",
    "X_poly_train = poly.fit_transform(X_train_scaled)\n",
    "X_poly_test = poly.transform(X_test_scaled)\n",
    "\n",
    "# Train the model on polynomial features \n",
    "poly_model = LinearRegression().fit(X_poly_train, y_train)\n",
    "\n",
    "# Make predictions using the polynomial model\n",
    "y_poly_pred_train = poly_model.predict(X_poly_train)\n",
    "y_poly_pred_test = poly_model.predict(X_poly_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "poly_rmse_train = np.sqrt(mean_squared_error(y_train, y_poly_pred_train))\n",
    "poly_rmse_test = np.sqrt(mean_squared_error(y_test, y_poly_pred_test))\n",
    "print(f'Poly LR RMSE Train: {poly_rmse_train}')\n",
    "print(f'Poly LR RMSE Test: {poly_rmse_test}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39446245-dfd5-4ddf-ba2e-e8689fd9b64d",
   "metadata": {},
   "source": [
    "## Ridge and Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c26a5473-c63e-4398-b16e-bae1e56ed287",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE (alpha = 10): 5.4523\n",
      "Test MSE (alpha = 10): 6.9659\n"
     ]
    }
   ],
   "source": [
    "# Create OLS instance and fit it\n",
    "ols = LinearRegression()\n",
    "ols.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Define a fixed alpha (lambda)\n",
    "alpha_fixed = 10\n",
    "\n",
    "# Create Ridge regression instance and fit it\n",
    "ridge = Ridge(alpha = alpha_fixed)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions using ridge model\n",
    "ridge_train_pred = ridge.predict(X_train_scaled)\n",
    "ridge_test_pred = ridge.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate MSE\n",
    "ridge_rmse_train = np.sqrt(mean_squared_error(y_train, ridge_train_pred))\n",
    "ridge_rmse_test = np.sqrt(mean_squared_error(y_test, ridge_test_pred))\n",
    "\n",
    "print(f\"Train MSE (alpha = {alpha_fixed}): {ridge_rmse_train:.4f}\")\n",
    "print(f\"Test MSE (alpha = {alpha_fixed}): {ridge_rmse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dad544c7-9a0e-4bb9-a3fe-b1abc5a4c440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeCV RMSE Train: 5.1930\n",
      "RidgeCV RMSE Test: 6.7328\n"
     ]
    }
   ],
   "source": [
    "# Try many alphas\n",
    "alphas = np.logspace(start = -4, stop = 4, num = 100)  # Alphas from 0.0001 to 10,000\n",
    "\n",
    "# Fit RidgeCV\n",
    "ridge_cv = RidgeCV(alphas = alphas, cv = 10).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions with the best alpha\n",
    "y_test_pred_cv = ridge_cv.predict(X_test_scaled)\n",
    "y_train_pred_cv = ridge_cv.predict(X_train_scaled)\n",
    "\n",
    "# Caculate RMSE\n",
    "ridgecv_rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred_cv))\n",
    "ridgecv_rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred_cv))\n",
    "\n",
    "print(f\"RidgeCV RMSE Train: {ridgecv_rmse_train:.4f}\")\n",
    "print(f\"RidgeCV RMSE Test: {ridgecv_rmse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4402df73-b13a-494b-a026-b516135bf3d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV RMSE Train: 5.3506\n",
      "LassoCV RMSE Test: 6.9606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1261.2238035733208, tolerance: 1168.548918093163\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    }
   ],
   "source": [
    "# Fit lasso regression with cross-validation\n",
    "lasso_cv = LassoCV(alphas = alphas, cv = 10, max_iter=10000).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "lassocv_test_pred = lasso_cv.predict(X_test_scaled)\n",
    "lassocv_train_pred = lasso_cv.predict(X_train_scaled)\n",
    "\n",
    "# Calculate RMSE\n",
    "lassocv_rmse_test = np.sqrt(mean_squared_error(y_test, lassocv_test_pred))\n",
    "lassocv_rmse_train = np.sqrt(mean_squared_error(y_train, lassocv_train_pred))\n",
    "\n",
    "print(f\"LassoCV RMSE Train: {lassocv_rmse_train:.4f}\")\n",
    "print(f\"LassoCV RMSE Test: {lassocv_rmse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e215363-a2bd-4bbd-8675-689aff050bd5",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e93aa28-b6d6-48b2-90ce-d894f288ef44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS Best Parameters: {'max_depth': 7, 'max_features': 6, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "\n",
      "RF RMSE Train: 3.407\n",
      "RF RMSE Test: 6.993\n",
      "\n",
      "Feature Importances:\n",
      "               Feature  Importance\n",
      "0               PO4uM    0.318997\n",
      "1              SiO3uM    0.231175\n",
      "2   R_Oxy_micromol.Kg    0.145176\n",
      "3               R_Sal    0.096353\n",
      "4           Salinity1    0.067644\n",
      "5               NO3uM    0.058657\n",
      "6                 TA1    0.028580\n",
      "7              R_TEMP    0.024043\n",
      "8             R_Depth    0.012058\n",
      "9    Temperature_degC    0.011295\n",
      "10            R_DYNHT    0.004388\n",
      "11              NO2uM    0.001267\n",
      "12                 id    0.000098\n",
      "13            Lon_Dec    0.000091\n",
      "14            Lat_Dec    0.000089\n",
      "15              NH3uM    0.000056\n",
      "16             R_Nuts    0.000034\n"
     ]
    }
   ],
   "source": [
    "# Construct parameter grid\n",
    "param_grid = {\n",
    "    \"max_features\":[\"sqrt\", 6, None],\n",
    "    \"n_estimators\":[50, 100, 200],\n",
    "    \"max_depth\":[3,4,5,6,7],\n",
    "    \"min_samples_split\":[2,5,10],\n",
    "    \"min_samples_leaf\":[1,2,4]\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize Random forest regressor\n",
    "rf = RandomForestRegressor(random_state = 808)\n",
    "\n",
    "# Use cross-validation to find best combo of parameter values\n",
    "gs = GridSearchCV(rf, param_grid = param_grid, n_jobs = -1, \n",
    "                  return_train_score = True, scoring = \"neg_mean_squared_error\")\n",
    "gs.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print best combo of parameters\n",
    "print(f\"GS Best Parameters: {gs.best_params_}\")\n",
    "\n",
    "# Train the best estimator\n",
    "best_rf = RandomForestRegressor(**gs.best_params_, random_state = 808)\n",
    "best_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate predictions\n",
    "rf_pred_train = best_rf.predict(X_train_scaled)\n",
    "rf_pred_test = best_rf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE\n",
    "rf_rmse_train = np.sqrt(mean_squared_error(y_train, rf_pred_train))\n",
    "rf_rmse_test = np.sqrt(mean_squared_error(y_test, rf_pred_test))\n",
    "print(f\"\\nRF RMSE Train: {rf_rmse_train:.3f}\")\n",
    "print(f\"RF RMSE Test: {rf_rmse_test:.3f}\")\n",
    "\n",
    "# Extract feature importance from RF model\n",
    "importance = best_rf.feature_importances_\n",
    "\n",
    "# Create a list of feature names\n",
    "feature_names = X_train_scaled.columns\n",
    "\n",
    "# Create feature importance df\n",
    "importance_df = (pd.DataFrame(zip(feature_names, importance), columns=['Feature', 'Importance'])\n",
    "                 .sort_values(by = 'Importance', key = abs, ascending = False)\n",
    "                 .reset_index(drop=True))\n",
    "\n",
    "# Print the sorted feature importance\n",
    "print(\"\\nFeature Importances:\\n\", importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df73af87-8c3c-4310-a96d-438560dcdeb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Filtered RMSE Train: 3.258669015911448\n",
      "RF Filtered RMSE Test: 6.977185484989777\n"
     ]
    }
   ],
   "source": [
    "# Try only using most important features\n",
    "filtered_train = X_train_scaled[['PO4uM', 'SiO3uM', 'R_Oxy_micromol.Kg', 'R_Sal', \n",
    "                                 'Salinity1', 'NO3uM', 'TA1', 'R_TEMP', 'R_Depth']]\n",
    "filtered_test = X_test_scaled[['PO4uM', 'SiO3uM', 'R_Oxy_micromol.Kg', 'R_Sal', \n",
    "                               'Salinity1', 'NO3uM', 'TA1', 'R_TEMP', 'R_Depth']]\n",
    "\n",
    "# Fit\n",
    "best_rf.fit(filtered_train, y_train)\n",
    "\n",
    "# Predict\n",
    "rf_filtered_train_preds = best_rf.predict(filtered_train)\n",
    "rf_filtered_test_preds = best_rf.predict(filtered_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rf_filtered_rmse_train = np.sqrt(mean_squared_error(y_train, rf_filtered_train_preds))\n",
    "rf_filtered_rmse_test = np.sqrt(mean_squared_error(y_test, rf_filtered_test_preds))\n",
    "\n",
    "print(\"RF Filtered RMSE Train:\", rf_filtered_rmse_train)\n",
    "print(\"RF Filtered RMSE Test:\", rf_filtered_rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc2981-5f37-4347-9c39-a090819c7c7a",
   "metadata": {},
   "source": [
    "## Comparing models\n",
    "\n",
    "Let's compare all of those models side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2b467570-1424-4df8-a437-f020f4d99c91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train: 5.3678\n",
      "SVM Test: 7.2435\n",
      "\n",
      "XGBoost Train: 0.2130\n",
      "XGBoost Test: 6.6148\n",
      "\n",
      "KNN Train: 9.1460\n",
      "KNN Test: 12.5296\n",
      "\n",
      "DT Train: 0.0000\n",
      "DT Test: 9.0706\n",
      "\n",
      "Bagging Train: 3.5750\n",
      "Bagging Test: 7.0812\n",
      "\n",
      "Linear Regression Train: 5.1814\n",
      "Linear Regression Test: 6.7242\n",
      "\n",
      "Poly LR Train: 3.7012\n",
      "Poly LR Test: 15.7480\n",
      "\n",
      "Ridge Train: 5.4523\n",
      "Ridge Test: 6.9659\n",
      "\n",
      "RidgeCV Train: 5.1930\n",
      "RidgeCV Test: 6.7328\n",
      "\n",
      "LassoCV Train: 5.3506\n",
      "LassoCV Test: 6.9606\n",
      "\n",
      "RF Train: 3.4072\n",
      "RF Test: 6.9926\n",
      "\n",
      "RF Filtered Train: 3.2587\n",
      "RF Filtered Test: 6.9772\n"
     ]
    }
   ],
   "source": [
    "print(f\"SVM Train: {svm_rmse_train:.4f}\")\n",
    "print(f\"SVM Test: {svm_rmse_test:.4f}\")\n",
    "print(f\"\\nXGBoost Train: {xgb_rmse_train:.4f}\")\n",
    "print(f\"XGBoost Test: {xgb_rmse_test:.4f}\")\n",
    "print(f'\\nKNN Train: {knn_train_rmse:.4f}')\n",
    "print(f'KNN Test: {knn_test_rmse:.4f}')\n",
    "print(f'\\nDT Train: {dt_train_rmse:.4f}')\n",
    "print(f'DT Test: {dt_test_rmse:.4f}')\n",
    "print(f'\\nBagging Train: {bag_train_rmse:.4f}')\n",
    "print(f'Bagging Test: {bag_test_rmse:.4f}')\n",
    "print(f'\\nLinear Regression Train: {lr_rmse_train:.4f}')\n",
    "print(f'Linear Regression Test: {lr_rmse_test:.4f}')\n",
    "print(f'\\nPoly LR Train: {poly_rmse_train:.4f}')\n",
    "print(f'Poly LR Test: {poly_rmse_test:.4f}')\n",
    "print(f\"\\nRidge Train: {ridge_rmse_train:.4f}\")\n",
    "print(f\"Ridge Test: {ridge_rmse_test:.4f}\")\n",
    "print(f\"\\nRidgeCV Train: {ridgecv_rmse_train:.4f}\")\n",
    "print(f\"RidgeCV Test: {ridgecv_rmse_test:.4f}\")\n",
    "print(f\"\\nLassoCV Train: {lassocv_rmse_train:.4f}\")\n",
    "print(f\"LassoCV Test: {lassocv_rmse_test:.4f}\")\n",
    "print(f\"\\nRF Train: {rf_rmse_train:.4f}\")\n",
    "print(f\"RF Test: {rf_rmse_test:.4f}\")\n",
    "print(f\"\\nRF Filtered Train: {rf_filtered_rmse_train:.4f}\")\n",
    "print(f\"RF Filtered Test: {rf_filtered_rmse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec611798-6cbb-40a6-beb1-0c304974c0fb",
   "metadata": {},
   "source": [
    "Out of these, XGBoost performed best on the testing data, but I saw a big change between the training and the testing scores.\n",
    "\n",
    "Following is the Linear Regression and Ridge CV. I will try these 3 as submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1783d18-ae4f-4988-84ed-3f98a5d62111",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9633d4a-c135-4591-95cd-9b05bf8138a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### XBG Submission ######\n",
    "\n",
    "# Generate final predictions on real test data\n",
    "test = scaler.fit_transform(final_test)\n",
    "# Predict\n",
    "pred = xgb_model.predict(test)\n",
    "\n",
    "# Make submission df\n",
    "# Create list of id\n",
    "ids = list(final_test.id)\n",
    "\n",
    "# Create list of DIC preds\n",
    "dic = list(pred)\n",
    "\n",
    "# Create submission df\n",
    "xgboost_submission_df = pd.DataFrame(zip(ids, dic), columns=['id', 'DIC'])\n",
    "xgboost_submission_df.to_csv('xgboost_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2d530220-11b0-47a2-b81a-525b07cee070",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-env/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "###### Linear Regression Submission ######\n",
    "\n",
    "# Generate final predictions on real test data\n",
    "test = scaler.fit_transform(final_test)\n",
    "# Predict\n",
    "pred = lr.predict(test)\n",
    "\n",
    "# Make submission df\n",
    "# Create list of id\n",
    "ids = list(final_test.id)\n",
    "\n",
    "# Create list of DIC preds\n",
    "dic = list(pred)\n",
    "\n",
    "# Create submission df\n",
    "lr_df = pd.DataFrame(zip(ids, dic), columns=['id', 'DIC'])\n",
    "lr_df.to_csv('lr-marina.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246931f2-980e-4ee0-b395-29e85477d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RidgeCV Submission ######\n",
    "\n",
    "# Generate final predictions on real test data\n",
    "test = scaler.fit_transform(final_test)\n",
    "# Predict\n",
    "pred = ridge_cv.predict(test)\n",
    "\n",
    "# Make submission df\n",
    "# Create list of id\n",
    "ids = list(final_test.id)\n",
    "\n",
    "# Create list of DIC preds\n",
    "dic = list(pred)\n",
    "\n",
    "# Create submission df\n",
    "ridgecv_df = pd.DataFrame(zip(ids, dic), columns=['id', 'DIC'])\n",
    "ridgecv_df.to_csv('ridgecv.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda 3 (EDS232)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
